"""Main orchestrator â€” runs scrapers, applies filters, generates report."""

from __future__ import annotations

import json
import os
import sys
import time

import httpx

from scrapers import (
    CLSScraper,
    Jin10Scraper,
    FutuScraper,
    EastmoneyNewsScraper,
    EastmoneyGubaScraper,
)
from filters import tag_precious_metals
from formatter import generate_report

# LLM Configuration - hardcoded for deployment
LLM_BASE_URL = "https://api.ephone.chat/v1/chat/completions"
LLM_API_KEY = "sk-8BXSZEmvWaM3qanlEMt4eRcDqLjQrh44rWwiNevSfSZ0Sxcl"
LLM_MODEL_POOL = [
    "gemini-3-flash-preview",
    "gemini-3-pro-preview",
    "gpt-5.2",
    "glm-4.7"
]

# Progress tracking
PROGRESS_FILE = os.path.join(os.path.dirname(__file__), "output", "progress.json")


def update_progress(current: int, total: int, message: str = ""):
    """Update progress file for frontend to read."""
    progress_data = {
        "current": current,
        "total": total,
        "percentage": int((current / total) * 100) if total > 0 else 0,
        "message": message,
    }
    with open(PROGRESS_FILE, "w", encoding="utf-8") as f:
        json.dump(progress_data, f, ensure_ascii=False)


def generate_topics_with_llm(
    articles: list,
    user_profile: str,
    persona_name: str = "",
) -> str:
    """Use LLM to generate personalized topic recommendations for the persona.

    Returns the raw markdown text from the LLM.
    """
    # Build headline list with source and URL
    headline_entries = []
    title_url_map: dict[str, str] = {}
    for a in articles:
        entry = f"- ã€{a.source}ã€‘{a.title}"
        if a.url:
            entry += f"ï¼ˆ{a.url}ï¼‰"
            title_url_map[a.title] = a.url
        headline_entries.append(entry)

    headlines = "\n".join(headline_entries)

    prompt = f"""ä½ çš„ä»»åŠ¡
æ ¹æ®ä»¥ä¸‹æä¾›çš„ã€æ–°é—»ç´ æã€‘å’Œã€è¾¾äººç”»åƒã€‘ï¼Œä¸ºè¯¥è¾¾äººç”Ÿæˆä¸€ä»½ä¸ªæ€§åŒ–çš„é€‰é¢˜æ¨èåˆ—è¡¨ã€‚

è¾“å…¥

è¾¾äººç”»åƒ
{user_profile}

ä»Šæ—¥æ–°é—»ç´ æ
{headlines}

æ¨èé€»è¾‘

è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ€è€ƒï¼š

1. ç†è§£è¾¾äººå®šä½ï¼šåˆ†æè¾¾äººçš„å†…å®¹é£æ ¼ã€æ ¸å¿ƒé¢†åŸŸã€ç›®æ ‡å—ä¼—å’Œæƒ¯ç”¨è§’åº¦ã€‚
2. ç­›é€‰ç›¸å…³ç´ æï¼šä»æ‰€æœ‰æ–°é—»æºä¸­ï¼ŒæŒ‘é€‰ä¸è¾¾äººå®šä½ç›¸å…³çš„æ–°é—»ï¼ˆç›´æ¥ç›¸å…³æˆ–å¯å»¶ä¼¸å…³è”ï¼‰ã€‚
3. ç”Ÿæˆé€‰é¢˜ï¼šå°†ç­›é€‰å‡ºçš„ç´ æè½¬åŒ–ä¸ºé€‚åˆè¯¥è¾¾äººé£æ ¼çš„å…·ä½“é€‰é¢˜ï¼Œè€Œéç®€å•å¤è¿°æ ‡é¢˜ã€‚æ¯ä¸ªé€‰é¢˜åº”ä½“ç°è¾¾äººçš„ç‹¬ç‰¹è§†è§’å’Œè¡¨è¾¾æ–¹å¼ã€‚
4. æ’åºä¸åˆ†ç±»ï¼šæŒ‰ç›¸å…³åº¦å’Œæ—¶æ•ˆæ€§æ’åºã€‚

è¾“å‡ºæ ¼å¼

è¯·è¾“å‡º 8-15 ä¸ªé€‰é¢˜å»ºè®®ï¼Œæ¯ä¸ªé€‰é¢˜åŒ…å«ï¼š

- é€‰é¢˜æ ‡é¢˜ï¼šä¸€å¥é€‚åˆè¯¥è¾¾äººé£æ ¼çš„æ ‡é¢˜ï¼ˆå¯ç›´æ¥ç”¨äºè§†é¢‘/æ–‡ç« ï¼‰
- æ ¸å¿ƒè§’åº¦ï¼šç”¨ä¸€å¥è¯è¯´æ˜è¿™ä¸ªé€‰é¢˜çš„åˆ‡å…¥ç‚¹
- ç´ ææ¥æºï¼šå¼•ç”¨äº†å“ªæ¡/å“ªå‡ æ¡æ–°é—»ï¼Œå¿…é¡»ä½¿ç”¨ Markdown è¶…é“¾æ¥æ ¼å¼ [æ–°é—»æ ‡é¢˜](URL)
- æ¨èç†ç”±ï¼šä¸ºä»€ä¹ˆè¿™ä¸ªé€‰é¢˜é€‚åˆè¯¥è¾¾äººï¼ˆ1-2å¥ï¼‰
- çƒ­åº¦è¯„çº§ï¼šğŸ”¥ï¼ˆé«˜ï¼‰/ ğŸ”¶ï¼ˆä¸­ï¼‰/ âšªï¼ˆä½ï¼‰

æ³¨æ„äº‹é¡¹
- ä¼˜å…ˆæ¨èæœ‰äº‰è®®æ€§ã€æœ‰è§‚ç‚¹ç©ºé—´çš„è¯é¢˜ï¼Œè€Œéçº¯èµ„è®¯ç±»æ–°é—»
- å¯ä»¥å°†å¤šæ¡ç›¸å…³æ–°é—»åˆå¹¶ä¸ºä¸€ä¸ªæ›´æœ‰æ·±åº¦çš„é€‰é¢˜
- é€‰é¢˜è¦æœ‰"é’©å­"â€”â€”èƒ½å¼•å‘è§‚ä¼—å¥½å¥‡æˆ–å…±é¸£
- é¿å…æ¨èä¸è¾¾äººå®šä½å®Œå…¨æ— å…³çš„å†…å®¹ï¼Œå³ä½¿è¯¥æ–°é—»å¾ˆçƒ­é—¨
- å¦‚æœæŸæ¡é‡å¤§æ–°é—»ä¸è¾¾äººé¢†åŸŸæœ‰é—´æ¥å…³è”ï¼Œå¯ä»¥å»ºè®®ä¸€ä¸ª"è·¨ç•Œè§£è¯»"è§’åº¦

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ Markdown æ ¼å¼è¾“å‡ºï¼Œæ³¨æ„ä½¿ç”¨æ­£ç¡®çš„ Markdown æ ‡é¢˜å±‚çº§å’Œæ¢è¡Œï¼š

## {persona_name} Â· ä»Šæ—¥é€‰é¢˜æ¨è

---

### é€‰é¢˜1ï¼šé€‰é¢˜æ ‡é¢˜

- **æ ¸å¿ƒè§’åº¦**ï¼š...
- **ç´ ææ¥æº**ï¼š[æ–°é—»æ ‡é¢˜1](URL1)ã€[æ–°é—»æ ‡é¢˜2](URL2)
- **æ¨èç†ç”±**ï¼š...
- **çƒ­åº¦è¯„çº§**ï¼šğŸ”¥/ğŸ”¶/âšª

---

### é€‰é¢˜2ï¼šé€‰é¢˜æ ‡é¢˜

- **æ ¸å¿ƒè§’åº¦**ï¼š...
- **ç´ ææ¥æº**ï¼š[æ–°é—»æ ‡é¢˜](URL)
- **æ¨èç†ç”±**ï¼š...
- **çƒ­åº¦è¯„çº§**ï¼šğŸ”¥/ğŸ”¶/âšª

...

### æ€»ç»“æ’åºå»ºè®®

è¯´æ˜ä¼˜å…ˆäº§å‡ºå“ªå‡ ä¸ªé€‰é¢˜åŠåŸå› ã€‚"""

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {LLM_API_KEY}",
    }
    payload = {
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.3,
    }

    for i, model in enumerate(LLM_MODEL_POOL):
        print(f"æ­£åœ¨è°ƒç”¨ LLM ç”Ÿæˆé€‰é¢˜æ¨è (æ¨¡å‹: {model})...")
        payload["model"] = model
        try:
            resp = httpx.post(
                LLM_BASE_URL,
                headers=headers,
                json=payload,
                timeout=120,
            )
            resp.raise_for_status()
            content = resp.json()["choices"][0]["message"]["content"]
            break
        except Exception as e:
            print(f"æ¨¡å‹ {model} è°ƒç”¨å¤±è´¥: {e}")
            if i == len(LLM_MODEL_POOL) - 1:
                raise

    # Strip markdown code fences if present
    content = content.strip()
    if content.startswith("```"):
        content = content.split("\n", 1)[1]
    if content.endswith("```"):
        content = content.rsplit("```", 1)[0]
    content = content.strip()

    # Post-process: replace plain-text title references with markdown links
    content = _linkify_titles(content, title_url_map)

    return content


def _linkify_titles(text: str, title_url_map: dict[str, str]) -> str:
    """Replace plain-text news title mentions with markdown hyperlinks.

    Skips titles that are already inside a markdown link [...](url).
    Sorts by title length descending to avoid partial matches.
    """
    import re
    for title in sorted(title_url_map, key=len, reverse=True):
        url = title_url_map[title]
        # Skip if this title is already a markdown link somewhere
        escaped = re.escape(title)
        # Match the title only when NOT already inside [...](...)
        # i.e. not preceded by [ or followed by ](
        pattern = r"(?<!\[)" + escaped + r"(?!\]\()"
        replacement = f"[{title}]({url})"
        text = re.sub(pattern, replacement, text, count=0)
    return text


def main():
    # Read user profile and persona name from command line arguments
    user_profile = ""
    persona_name = ""
    if len(sys.argv) > 1:
        user_profile = sys.argv[1]
    if len(sys.argv) > 2:
        persona_name = sys.argv[2]

    all_articles = []
    all_errors = []

    scrapers = [
        CLSScraper(),
        Jin10Scraper(),
        FutuScraper(),
        EastmoneyNewsScraper(),
        EastmoneyGubaScraper(),
    ]

    # Total steps: scrapers + filter + LLM + report generation
    total_steps = len(scrapers) + 3
    current_step = 0

    for i, scraper in enumerate(scrapers):
        current_step += 1
        update_progress(current_step, total_steps, f"æ­£åœ¨æŠ“å– {scraper.source_name}...")
        print(f"[{scraper.source_name}] æ­£åœ¨æŠ“å–...")
        articles, errors = scraper.fetch()
        print(f"[{scraper.source_name}] è·å– {len(articles)} ç¯‡æ–‡ç« ")
        if errors:
            for err in errors:
                print(f"[{scraper.source_name}] é”™è¯¯: {err[:200]}")
        all_articles.extend(articles)
        all_errors.extend(errors)

        # Small delay between scrapers
        if i < len(scrapers) - 1:
            time.sleep(1.5)

    # Apply precious metals filter
    current_step += 1
    update_progress(current_step, total_steps, "æ­£åœ¨ç­›é€‰è´µé‡‘å±ç›¸å…³æ–‡ç« ...")
    print(f"\nå…±è·å– {len(all_articles)} ç¯‡æ–‡ç« ï¼Œæ­£åœ¨ç­›é€‰è´µé‡‘å±ç›¸å…³...")
    tag_precious_metals(all_articles)
    precious_count = sum(1 for a in all_articles if a.is_precious_metals)
    print(f"è´µé‡‘å±ç›¸å…³: {precious_count} ç¯‡")

    # LLM personalized topic recommendations
    topics_md = ""
    if user_profile:
        try:
            current_step += 1
            update_progress(current_step, total_steps, "æ­£åœ¨ç”Ÿæˆé€‰é¢˜æ¨è...")
            topics_md = generate_topics_with_llm(all_articles, user_profile, persona_name or "è¾¾äºº")
            print(f"LLM é€‰é¢˜æ¨èå·²ç”Ÿæˆ")
        except Exception as e:
            print(f"LLM é€‰é¢˜æ¨èå¤±è´¥: {e}")
    else:
        current_step += 1
        print("æœªæä¾›è¾¾äººç”»åƒï¼Œè·³è¿‡é€‰é¢˜æ¨è")

    # Generate report
    current_step += 1
    update_progress(current_step, total_steps, "æ­£åœ¨ç”ŸæˆæŠ¥å‘Š...")
    filepath = generate_report(all_articles, all_errors, topics_md, user_profile, persona_name)
    print(f"\næŠ¥å‘Šå·²ç”Ÿæˆ: {filepath}")

    # Clear progress file
    if os.path.exists(PROGRESS_FILE):
        os.remove(PROGRESS_FILE)


if __name__ == "__main__":
    main()
